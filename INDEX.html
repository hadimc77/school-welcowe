<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Welcome to Crescent</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      text-align: center;
      font-family: 'Segoe UI', sans-serif;
      background: #e0f7fa;
      margin: 0;
      padding: 20px;
    }

    h1 {
      color: #006064;
      margin-bottom: 20px;
    }

    #camera-container {
      position: relative;
      display: inline-block;
      border: 8px solid #006064;
      border-radius: 20px;
      overflow: hidden;
      width: 90vw;
      max-width: 400px;
    }

    video, canvas {
      width: 100%;
      height: auto;
    }

    #greeting {
      display: none;
    }
  </style>
</head>
<body>

  <h1>ðŸŽ“ Welcome to Crescent</h1>

  <div id="camera-container">
    <video id="video" autoplay muted playsinline></video>
    <!-- The face detection box will draw over this canvas -->
  </div>

  <audio id="greeting" src="welcome to school.mp3"></audio>

  <script>
    const video = document.getElementById('video');
    const audio = document.getElementById('greeting');
    let hasGreeted = false;

    // Load Face API model
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models')
    ]).then(startVideo);

    // Ask for camera permission and start video
    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => {
          alert("Camera permission is required to greet students. Please allow camera access.");
          console.error("Camera error: ", err);
        });
    }

    video.addEventListener('play', () => {
      const canvas = faceapi.createCanvasFromMedia(video);
      document.getElementById('camera-container').append(canvas);

      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
        const resized = faceapi.resizeResults(detections, displaySize);

        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resized);

        if (detections.length > 0 && !hasGreeted) {
          audio.play();
          hasGreeted = true;
          setTimeout(() => hasGreeted = false, 6000); // reset after 6 seconds
        }
      }, 500);
    });
  </script>

</body>
</html>
